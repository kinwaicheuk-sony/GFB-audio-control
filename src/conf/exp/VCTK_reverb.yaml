num_workers: 1

task: "reverb"

#training related parameters
batch_size: 2
optimizer:
  _target_: torch.optim.Adam
  lr: 1e-4
  betas: [0.9, 0.999]

#lr_rampup_it: 10000 # 'Learning rate rampup duration'
lr_rampup_it: 10 # 'Learning rate rampup duration'

cudnn_bench: True 

segment_length: 65536
fs: 16000

cudnn_autotuner: False #autotune cudnn for the best performance

max_steps: 10000000 #maximum number of steps to train

#gradient clipping
use_grad_clip: True
max_grad_norm: 1 #1

conditional: True

